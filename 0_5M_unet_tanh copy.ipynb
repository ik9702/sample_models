{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb472d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d39d969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vb import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e41c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = CustomDataset(train=True, target_len=2**13)\n",
    "# test_dataset = CustomDataset(train=False, target_len=2**13, fixed=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2246effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('train_dataset.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('test_dataset.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_dataset, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c08041e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_dataset.pkl', 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "with open('test_dataset.pkl', 'rb') as f:\n",
    "    test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f169574f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d2be0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493327"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class CBP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CBP, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, 3, 1, padding=1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "    def forward(self, x, residual=None):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if residual==None:\n",
    "            x = self.prelu(x)\n",
    "        else:\n",
    "            x = self.prelu(x+residual)\n",
    "        return x\n",
    "        \n",
    "class Pool(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Pool, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, in_channels, 2, 2, padding=0)\n",
    "        self.bn = nn.BatchNorm1d(in_channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.prelu(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "class unPool(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(unPool, self).__init__()\n",
    "        self.tconv = nn.ConvTranspose1d(in_channels, in_channels, 2, 2)\n",
    "        self.bn = nn.BatchNorm1d(in_channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.tconv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.prelu(x)\n",
    "        \n",
    "        return x\n",
    "          \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.residual = nn.Conv1d(in_channels, out_channels, 1)  # Skip connection\n",
    "        self.cbp11 = CBP(in_channels, out_channels)\n",
    "        self.cbp12 = CBP(out_channels, out_channels)\n",
    "        \n",
    "        self.cbp21 = CBP(out_channels, out_channels)\n",
    "        self.cbp22 = CBP(out_channels, out_channels)\n",
    "        \n",
    "        self.pool = Pool(out_channels)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        x = self.cbp11(x)\n",
    "        residual = self.cbp12(x, residual)\n",
    "        \n",
    "        x = self.cbp21(residual)\n",
    "        skip = self.cbp22(x, residual)\n",
    "        \n",
    "        x = self.pool(skip)\n",
    "        \n",
    "        return x, skip\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.unpool = unPool(in_channels)\n",
    "        self.residual = nn.Conv1d(in_channels, out_channels, 1)  # Skip connection\n",
    "        \n",
    "        self.cbp11 = CBP(in_channels*2, out_channels)\n",
    "        self.cbp12 = CBP(out_channels, out_channels)\n",
    "        \n",
    "        self.cbp21 = CBP(out_channels, out_channels)\n",
    "        self.cbp22 = CBP(out_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x, skip):\n",
    "        \n",
    "    \n",
    "        x = self.unpool(x)\n",
    "        residual = self.residual(x)\n",
    "        x = self.cbp11(torch.cat([x, skip], dim=1))\n",
    "        residual = self.cbp12(x, residual)\n",
    "    \n",
    "        x = self.cbp21(residual)\n",
    "        x = self.cbp22(x, residual)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Feature_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Feature_Encoder, self).__init__()\n",
    "        # Encoder blocks\n",
    "        self.encoder_block_1 = Encoder(1, 8)\n",
    "        self.encoder_block_2 = Encoder(8, 16)\n",
    "        self.encoder_block_3 = Encoder(16, 32)\n",
    "        self.encoder_block_4 = Encoder(32, 64)\n",
    "        self.encoder_block_5 = Encoder(64, 128)\n",
    "\n",
    "        # Decoder blocks\n",
    "        self.decoder_block_5 = Decoder(128, 64)\n",
    "        self.decoder_block_4 = Decoder(64, 32)\n",
    "        self.decoder_block_3 = Decoder(32, 16)\n",
    "        self.decoder_block_2 = Decoder(16, 8)\n",
    "        self.decoder_block_1 = Decoder(8, 8)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(8, 16, 3, 1, padding=1)  # Remove dilation\n",
    "        self.conv2 = nn.Conv1d(16, 32, 3, 1, padding=1)  # Remove dilation\n",
    "        self.conv3 = nn.Conv1d(32, 64, 3, 1, padding=1)\n",
    "        self.conv4 = nn.Conv1d(64, 128, 3, 1, padding=1)\n",
    "        self.conv7 = nn.Conv1d(128, 1, 1, 1)\n",
    "\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.prelu1 = nn.PReLU()\n",
    "        self.prelu2 = nn.PReLU()\n",
    "        self.prelu3 = nn.PReLU()\n",
    "        self.prelu4 = nn.PReLU()\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, skip1 = self.encoder_block_1(x)\n",
    "        out, skip2 = self.encoder_block_2(out)\n",
    "        out, skip3 = self.encoder_block_3(out)\n",
    "        out, skip4 = self.encoder_block_4(out)\n",
    "        out, skip5 = self.encoder_block_5(out)\n",
    "        \n",
    "        out = self.decoder_block_5(out, skip5)\n",
    "        out = self.decoder_block_4(out, skip4)\n",
    "        out = self.decoder_block_3(out, skip3)\n",
    "        out = self.decoder_block_2(out, skip2)\n",
    "        out = self.decoder_block_1(out, skip1)\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.prelu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.prelu2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.prelu3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.bn4(out)\n",
    "        out = self.prelu4(out)\n",
    "\n",
    "        out = self.conv7(out)\n",
    "\n",
    "        return self.tanh(out)\n",
    "\n",
    "model = Feature_Encoder()\n",
    "sample_input = torch.randn(64, 1, 8192)\n",
    "model(sample_input)\n",
    "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "trainable_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2d6c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True,drop_last=True)\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78684a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable parameters: 493327\n",
      "1 0.009841566385390858 0.005455110338516533\n",
      "11 0.0016458085647577214 0.0012423052685335279\n",
      "21 0.0011796479100464946 0.0008039500486726562\n",
      "31 0.0009145488490402285 0.0005335670939530246\n",
      "41 0.0007238560095882147 0.0003706049683387391\n",
      "51 0.0006308366457233206 0.00028605440820683725\n",
      "61 0.0005921532632783055 0.00025599062185695704\n",
      "71 0.0005588125770575263 0.00023529209526410946\n",
      "81 0.0005352863906106601 0.00023545399502230188\n",
      "91 0.0005290998721547011 0.0002190106145765943\n",
      "101 0.0005079836222446627 0.00022240525383191803\n",
      "111 0.000500962243111442 0.00020639850966593562\n",
      "121 0.000490267681177809 0.00019858916251299283\n",
      "131 0.00047976467823092307 0.00019644543499452993\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     25\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 26\u001b[0m     t_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# l_list.append(t_loss)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m t_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = 'cuda'\n",
    "model = Feature_Encoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "writer = SummaryWriter('boards/0_5M_unet_tanh')\n",
    "x_back = None\n",
    "l_list = []\n",
    "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('trainable parameters:', trainable_parameters)\n",
    "for epoch in range(0,100000000000):\n",
    "    t_loss = 0\n",
    "    model.train()\n",
    "    for clean, noisy in train_loader:\n",
    "        clean, noisy = clean.to(device), noisy.to(device)\n",
    "        \n",
    "        pred = model(noisy)\n",
    "        \n",
    "        loss = loss_fn(pred, clean)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_loss+=loss.item()\n",
    "    # l_list.append(t_loss)\n",
    "    t_loss /= len(train_loader)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        t_tloss = 0\n",
    "        for clean, noisy in test_loader:\n",
    "            clean, noisy = clean.to(device), noisy.to(device)\n",
    "            pred = model(noisy)\n",
    "            loss = loss_fn(pred, clean)\n",
    "            t_tloss+=loss.item()\n",
    "        # l_list.append(t_tloss)\n",
    "        t_tloss /= len(test_loader)\n",
    "        \n",
    "    writer.add_scalars('run_14h', {'train_loss':t_loss,\n",
    "                                        'test_loss':t_tloss}, epoch)\n",
    "    writer.flush()\n",
    "    if epoch%10==1:\n",
    "        print(epoch, t_loss, t_tloss)\n",
    "        try:\n",
    "            os.mkdir(\"ckpts/0_5M_unet_tanh\")\n",
    "        except:\n",
    "            pass\n",
    "        torch.save(model.state_dict(), f'ckpts/0_5M_unet_tanh/ckpt_{epoch}_.pt')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89556b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import librosa\n",
    "import torchaudio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4ce755b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/835 [00:00<?, ?it/s]100%|██████████| 835/835 [01:27<00:00,  9.54it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/test_dataset.txt\", 'r') as f:\n",
    "    test_list = f.readlines()\n",
    "    test_list = [x.strip() for x in test_list]\n",
    "\n",
    "clean_path = \"/workspace/nas-dataset/jis/voicebank_demand/clean_trainset_56spk_wav/\"\n",
    "noisy_path = \"/workspace/nas-dataset/jis/voicebank_demand/noisy_trainset_56spk_wav/\"\n",
    "x1_path = \"/workspace/nas-dataset/jis/VB_readymade/sample_enh/0_5M_unet/\"\n",
    "device = 'cuda'\n",
    "try:\n",
    "    os.mkdir(x1_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('ckpts/0_5M_unet_tanh/ckpt_131_.pt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, file in enumerate(tqdm.tqdm(test_list)):\n",
    "        clean, sr1 = librosa.load(os.path.join(clean_path, file), sr=16000,res_type='kaiser_best')\n",
    "        noisy, sr2 = librosa.load(os.path.join(noisy_path, file), sr=16000,res_type='kaiser_best')\n",
    "        \n",
    "        pad_size = 8192 - len(noisy)%8192\n",
    "        padded_noisy = np.pad(noisy, (0, pad_size), 'constant', constant_values=(0, 0))\n",
    "        x1 = model(torch.tensor(padded_noisy).float().view(1,1,-1).to(device)).cpu().detach().numpy().reshape(-1)[:len(clean)]\n",
    "        \n",
    "        torchaudio.save(os.path.join(x1_path, file), torch.tensor(x1).view(1,-1), 16000)\n",
    "        \n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed7772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "golf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb472d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d39d969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vb import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e41c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = CustomDataset(train=True, target_len=2**13)\n",
    "# test_dataset = CustomDataset(train=False, target_len=2**13, fixed=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2246effc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 824/824 [01:18<00:00, 10.55it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# with open('train_dataset.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('test_dataset.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_dataset, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08041e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_dataset.pkl', 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "with open('test_dataset.pkl', 'rb') as f:\n",
    "    test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f169574f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d2be0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1860247"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class CBP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CBP, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, 3, 1, padding=1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "    def forward(self, x, residual=None):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if residual==None:\n",
    "            x = self.prelu(x)\n",
    "        else:\n",
    "            x = self.prelu(x+residual)\n",
    "        return x\n",
    "        \n",
    "class Pool(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Pool, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, in_channels, 2, 2, padding=0)\n",
    "        self.bn = nn.BatchNorm1d(in_channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.prelu(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "class unPool(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(unPool, self).__init__()\n",
    "        self.tconv = nn.ConvTranspose1d(in_channels, in_channels, 2, 2)\n",
    "        self.bn = nn.BatchNorm1d(in_channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.tconv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.prelu(x)\n",
    "        \n",
    "        return x\n",
    "          \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.residual = nn.Conv1d(in_channels, out_channels, 1)  # Skip connection\n",
    "        self.cbp11 = CBP(in_channels, out_channels)\n",
    "        self.cbp12 = CBP(out_channels, out_channels)\n",
    "        \n",
    "        self.cbp21 = CBP(out_channels, out_channels)\n",
    "        self.cbp22 = CBP(out_channels, out_channels)\n",
    "        \n",
    "        self.pool = Pool(out_channels)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        x = self.cbp11(x)\n",
    "        residual = self.cbp12(x, residual)\n",
    "        \n",
    "        x = self.cbp21(residual)\n",
    "        skip = self.cbp22(x, residual)\n",
    "        \n",
    "        x = self.pool(skip)\n",
    "        \n",
    "        return x, skip\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.unpool = unPool(in_channels)\n",
    "        self.residual = nn.Conv1d(in_channels, out_channels, 1)  # Skip connection\n",
    "        \n",
    "        self.cbp11 = CBP(in_channels*2, out_channels)\n",
    "        self.cbp12 = CBP(out_channels, out_channels)\n",
    "        \n",
    "        self.cbp21 = CBP(out_channels, out_channels)\n",
    "        self.cbp22 = CBP(out_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x, skip):\n",
    "        \n",
    "    \n",
    "        x = self.unpool(x)\n",
    "        residual = self.residual(x)\n",
    "        x = self.cbp11(torch.cat([x, skip], dim=1))\n",
    "        residual = self.cbp12(x, residual)\n",
    "    \n",
    "        x = self.cbp21(residual)\n",
    "        x = self.cbp22(x, residual)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Feature_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Feature_Encoder, self).__init__()\n",
    "        # Encoder blocks\n",
    "        self.encoder_block_1 = Encoder(1, 16)\n",
    "        self.encoder_block_2 = Encoder(16, 32)\n",
    "        self.encoder_block_3 = Encoder(32, 64)\n",
    "        self.encoder_block_4 = Encoder(64, 128)\n",
    "        self.encoder_block_5 = Encoder(128, 256)\n",
    "\n",
    "        # Decoder blocks\n",
    "        self.decoder_block_5 = Decoder(256, 128)\n",
    "        self.decoder_block_4 = Decoder(128, 64)\n",
    "        self.decoder_block_3 = Decoder(64, 32)\n",
    "        self.decoder_block_2 = Decoder(32, 16)\n",
    "        self.decoder_block_1 = Decoder(16, 16)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(16, 16, 3, 1, padding=1)  # Remove dilation\n",
    "        self.conv2 = nn.Conv1d(16, 32, 3, 1, padding=1)  # Remove dilation\n",
    "        self.conv3 = nn.Conv1d(32, 64, 3, 1, padding=1)\n",
    "        self.conv4 = nn.Conv1d(64, 128, 3, 1, padding=1)\n",
    "        self.conv7 = nn.Conv1d(128, 1, 1, 1)\n",
    "\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.prelu1 = nn.PReLU()\n",
    "        self.prelu2 = nn.PReLU()\n",
    "        self.prelu3 = nn.PReLU()\n",
    "        self.prelu4 = nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, skip1 = self.encoder_block_1(x)\n",
    "        out, skip2 = self.encoder_block_2(out)\n",
    "        out, skip3 = self.encoder_block_3(out)\n",
    "        out, skip4 = self.encoder_block_4(out)\n",
    "        out, skip5 = self.encoder_block_5(out)\n",
    "        \n",
    "        out = self.decoder_block_5(out, skip5)\n",
    "        out = self.decoder_block_4(out, skip4)\n",
    "        out = self.decoder_block_3(out, skip3)\n",
    "        out = self.decoder_block_2(out, skip2)\n",
    "        out = self.decoder_block_1(out, skip1)\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.prelu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.prelu2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.prelu3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.bn4(out)\n",
    "        out = self.prelu4(out)\n",
    "\n",
    "        out = self.conv7(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = Feature_Encoder()\n",
    "sample_input = torch.randn(64, 1, 8192)\n",
    "model(sample_input)\n",
    "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "trainable_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d6c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True,drop_last=True)\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78684a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable parameters: 1860247\n",
      "1 0.013276073181380828 0.008472477202303708\n",
      "11 0.0016637162344219783 0.0012572383129736409\n",
      "21 0.001042173466218325 0.0006198301271069795\n",
      "31 0.0008076944116813441 0.0004334378803226476\n",
      "41 0.0006449492231089001 0.00029206398418561247\n",
      "51 0.000568528243942031 0.00024260403491401425\n",
      "61 0.000530562955504542 0.00023825467239172818\n",
      "71 0.00048648909610670267 0.00021541449556631656\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     25\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 26\u001b[0m     t_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# l_list.append(t_loss)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m t_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = 'cuda'\n",
    "model = Feature_Encoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "writer = SummaryWriter('boards/1_8M_unet')\n",
    "x_back = None\n",
    "l_list = []\n",
    "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('trainable parameters:', trainable_parameters)\n",
    "for epoch in range(0,100000000000):\n",
    "    t_loss = 0\n",
    "    model.train()\n",
    "    for clean, noisy in train_loader:\n",
    "        clean, noisy = clean.to(device), noisy.to(device)\n",
    "        \n",
    "        pred = model(noisy)\n",
    "        \n",
    "        loss = loss_fn(pred, clean)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_loss+=loss.item()\n",
    "    # l_list.append(t_loss)\n",
    "    t_loss /= len(train_loader)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        t_tloss = 0\n",
    "        for clean, noisy in test_loader:\n",
    "            clean, noisy = clean.to(device), noisy.to(device)\n",
    "            pred = model(noisy)\n",
    "            loss = loss_fn(pred, clean)\n",
    "            t_tloss+=loss.item()\n",
    "        # l_list.append(t_tloss)\n",
    "        t_tloss /= len(test_loader)\n",
    "        \n",
    "    writer.add_scalars('run_14h', {'train_loss':t_loss,\n",
    "                                        'test_loss':t_tloss}, epoch)\n",
    "    writer.flush()\n",
    "    if epoch%10==1:\n",
    "        print(epoch, t_loss, t_tloss)\n",
    "        try:\n",
    "            os.mkdir(\"ckpts/1_8M_unet\")\n",
    "        except:\n",
    "            pass\n",
    "        torch.save(model.state_dict(), f'ckpts/1_8M_unet/ckpt_{epoch}_.pt')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce755b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb472d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d39d969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vb import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e41c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = CustomDataset(train=True, target_len=2**13)\n",
    "# test_dataset = CustomDataset(train=False, target_len=2**13, fixed=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2246effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('train_dataset.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('test_dataset.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_dataset, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c08041e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_dataset.pkl', 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "with open('test_dataset.pkl', 'rb') as f:\n",
    "    test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f169574f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d2be0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1860247"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class CBP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CBP, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, 3, 1, padding=1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "    def forward(self, x, residual=None):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if residual==None:\n",
    "            x = self.prelu(x)\n",
    "        else:\n",
    "            x = self.prelu(x+residual)\n",
    "        return x\n",
    "        \n",
    "class Pool(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Pool, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, in_channels, 2, 2, padding=0)\n",
    "        self.bn = nn.BatchNorm1d(in_channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.prelu(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "class unPool(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(unPool, self).__init__()\n",
    "        self.tconv = nn.ConvTranspose1d(in_channels, in_channels, 2, 2)\n",
    "        self.bn = nn.BatchNorm1d(in_channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.tconv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.prelu(x)\n",
    "        \n",
    "        return x\n",
    "          \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.residual = nn.Conv1d(in_channels, out_channels, 1)  # Skip connection\n",
    "        self.cbp11 = CBP(in_channels, out_channels)\n",
    "        self.cbp12 = CBP(out_channels, out_channels)\n",
    "        \n",
    "        self.cbp21 = CBP(out_channels, out_channels)\n",
    "        self.cbp22 = CBP(out_channels, out_channels)\n",
    "        \n",
    "        self.pool = Pool(out_channels)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        x = self.cbp11(x)\n",
    "        residual = self.cbp12(x, residual)\n",
    "        \n",
    "        x = self.cbp21(residual)\n",
    "        skip = self.cbp22(x, residual)\n",
    "        \n",
    "        x = self.pool(skip)\n",
    "        \n",
    "        return x, skip\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.unpool = unPool(in_channels)\n",
    "        self.residual = nn.Conv1d(in_channels, out_channels, 1)  # Skip connection\n",
    "        \n",
    "        self.cbp11 = CBP(in_channels*2, out_channels)\n",
    "        self.cbp12 = CBP(out_channels, out_channels)\n",
    "        \n",
    "        self.cbp21 = CBP(out_channels, out_channels)\n",
    "        self.cbp22 = CBP(out_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x, skip):\n",
    "        \n",
    "    \n",
    "        x = self.unpool(x)\n",
    "        residual = self.residual(x)\n",
    "        x = self.cbp11(torch.cat([x, skip], dim=1))\n",
    "        residual = self.cbp12(x, residual)\n",
    "    \n",
    "        x = self.cbp21(residual)\n",
    "        x = self.cbp22(x, residual)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Feature_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Feature_Encoder, self).__init__()\n",
    "        # Encoder blocks\n",
    "        self.encoder_block_1 = Encoder(1, 16)\n",
    "        self.encoder_block_2 = Encoder(16, 32)\n",
    "        self.encoder_block_3 = Encoder(32, 64)\n",
    "        self.encoder_block_4 = Encoder(64, 128)\n",
    "        self.encoder_block_5 = Encoder(128, 256)\n",
    "\n",
    "        # Decoder blocks\n",
    "        self.decoder_block_5 = Decoder(256, 128)\n",
    "        self.decoder_block_4 = Decoder(128, 64)\n",
    "        self.decoder_block_3 = Decoder(64, 32)\n",
    "        self.decoder_block_2 = Decoder(32, 16)\n",
    "        self.decoder_block_1 = Decoder(16, 16)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(16, 16, 3, 1, padding=1)  # Remove dilation\n",
    "        self.conv2 = nn.Conv1d(16, 32, 3, 1, padding=1)  # Remove dilation\n",
    "        self.conv3 = nn.Conv1d(32, 64, 3, 1, padding=1)\n",
    "        self.conv4 = nn.Conv1d(64, 128, 3, 1, padding=1)\n",
    "        self.conv7 = nn.Conv1d(128, 1, 1, 1)\n",
    "\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.prelu1 = nn.PReLU()\n",
    "        self.prelu2 = nn.PReLU()\n",
    "        self.prelu3 = nn.PReLU()\n",
    "        self.prelu4 = nn.PReLU()\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, skip1 = self.encoder_block_1(x)\n",
    "        out, skip2 = self.encoder_block_2(out)\n",
    "        out, skip3 = self.encoder_block_3(out)\n",
    "        out, skip4 = self.encoder_block_4(out)\n",
    "        out, skip5 = self.encoder_block_5(out)\n",
    "        \n",
    "        out = self.decoder_block_5(out, skip5)\n",
    "        out = self.decoder_block_4(out, skip4)\n",
    "        out = self.decoder_block_3(out, skip3)\n",
    "        out = self.decoder_block_2(out, skip2)\n",
    "        out = self.decoder_block_1(out, skip1)\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.prelu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.prelu2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.prelu3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.bn4(out)\n",
    "        out = self.prelu4(out)\n",
    "\n",
    "        out = self.conv7(out)\n",
    "\n",
    "        return self.tanh(out)\n",
    "\n",
    "model = Feature_Encoder()\n",
    "sample_input = torch.randn(64, 1, 8192)\n",
    "model(sample_input)\n",
    "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "trainable_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d6c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True,drop_last=True)\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78684a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable parameters: 1860247\n",
      "1 0.009765791065163083 0.006257620290853083\n",
      "11 0.001557788479840383 0.0011931456053086247\n",
      "21 0.0010129221110320133 0.0005796091378821681\n",
      "31 0.000732606990075308 0.00038247361226240173\n",
      "41 0.0006182024648296647 0.0003080479024598996\n",
      "51 0.0005485252194274734 0.0002661102128816613\n",
      "61 0.0005177123934522064 0.0002384260684872667\n",
      "71 0.0004943805924590884 0.00022900637729132237\n",
      "81 0.0004717807602396028 0.00020546807354548946\n",
      "91 0.00045328459107420513 0.00021793483877748562\n",
      "101 0.00044585900743388467 0.00020674548795796\n",
      "111 0.00043199921670343934 0.0001895040416760215\n",
      "121 0.0004254064081275525 0.00017709269195620436\n",
      "131 0.00042027140467932136 0.00018418588782272613\n",
      "141 0.0004105527038013356 0.00016874173707037698\n",
      "151 0.00040743052175255595 0.0001801531592112345\n",
      "161 0.0004001797050780927 0.00016823881499779722\n",
      "171 0.0003944739515847889 0.00016570800107729156\n",
      "181 0.00038809189233385646 0.00017636065240367316\n",
      "191 0.00037861013624933547 0.00015734054795757402\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     25\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 26\u001b[0m     t_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# l_list.append(t_loss)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m t_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = 'cuda'\n",
    "model = Feature_Encoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "writer = SummaryWriter('boards/1_8M_unet_tanh')\n",
    "x_back = None\n",
    "l_list = []\n",
    "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('trainable parameters:', trainable_parameters)\n",
    "for epoch in range(0,100000000000):\n",
    "    t_loss = 0\n",
    "    model.train()\n",
    "    for clean, noisy in train_loader:\n",
    "        clean, noisy = clean.to(device), noisy.to(device)\n",
    "        \n",
    "        pred = model(noisy)\n",
    "        \n",
    "        loss = loss_fn(pred, clean)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_loss+=loss.item()\n",
    "    # l_list.append(t_loss)\n",
    "    t_loss /= len(train_loader)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        t_tloss = 0\n",
    "        for clean, noisy in test_loader:\n",
    "            clean, noisy = clean.to(device), noisy.to(device)\n",
    "            pred = model(noisy)\n",
    "            loss = loss_fn(pred, clean)\n",
    "            t_tloss+=loss.item()\n",
    "        # l_list.append(t_tloss)\n",
    "        t_tloss /= len(test_loader)\n",
    "        \n",
    "    writer.add_scalars('run_14h', {'train_loss':t_loss,\n",
    "                                        'test_loss':t_tloss}, epoch)\n",
    "    writer.flush()\n",
    "    if epoch%10==1:\n",
    "        print(epoch, t_loss, t_tloss)\n",
    "        try:\n",
    "            os.mkdir(\"ckpts/1_8M_unet_tanh\")\n",
    "        except:\n",
    "            pass\n",
    "        torch.save(model.state_dict(), f'ckpts/1_8M_unet_tanh/ckpt_{epoch}_.pt')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ce755b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 461/835 [01:02<00:50,  7.35it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m padded_noisy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(x1, (\u001b[38;5;241m0\u001b[39m, pad_size), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m, constant_values\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     31\u001b[0m x2 \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mtensor(padded_noisy)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[:\u001b[38;5;28mlen\u001b[39m(clean)]\n\u001b[0;32m---> 33\u001b[0m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# break\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/golf/lib/python3.11/site-packages/torchaudio/backend/sox_io_backend.py:429\u001b[0m, in \u001b[0;36msave\u001b[0;34m(filepath, src, sample_rate, channels_first, compression, format, encoding, bits_per_sample)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    428\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(filepath)\n\u001b[0;32m--> 429\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msox_io_save_audio_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbits_per_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/golf/lib/python3.11/site-packages/torch/_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import librosa\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "device = 'cuda'\n",
    "\n",
    "with open(\"data/test_dataset.txt\", 'r') as f:\n",
    "    test_list = f.readlines()\n",
    "    test_list = [x.strip() for x in test_list]\n",
    "\n",
    "clean_path = \"/workspace/nas-dataset/jis/voicebank_demand/clean_trainset_56spk_wav/\"\n",
    "noisy_path = \"/workspace/nas-dataset/jis/voicebank_demand/noisy_trainset_56spk_wav/\"\n",
    "x1_path = \"/workspace/nas-dataset/jis/VB_readymade/sample_enh/1_8M_unet/\"\n",
    "x2_path = \"/workspace/nas-dataset/jis/VB_readymade/sample_enh/x2_1_8M_unet/\"\n",
    "try:\n",
    "    os.mkdir(x2_path)\n",
    "except:\n",
    "    pass\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('ckpts/1_8M_unet_tanh/ckpt_191_.pt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, file in enumerate(tqdm.tqdm(test_list)):\n",
    "        clean, sr1 = librosa.load(os.path.join(clean_path, file), sr=16000,res_type='kaiser_best')\n",
    "        noisy, sr2 = librosa.load(os.path.join(noisy_path, file), sr=16000,res_type='kaiser_best')\n",
    "        x1, sr2 = librosa.load(os.path.join(x1_path, file), sr=16000,res_type='kaiser_best')\n",
    "        \n",
    "        \n",
    "        pad_size = 8192 - len(x1)%8192\n",
    "        padded_noisy = np.pad(x1, (0, pad_size), 'constant', constant_values=(0, 0))\n",
    "        x2 = model(torch.tensor(padded_noisy).float().view(1,1,-1).to(device)).cpu().detach().numpy().reshape(-1)[:len(clean)]\n",
    "        \n",
    "        torchaudio.save(os.path.join(x2_path, file), torch.tensor(x2).view(1,-1), 16000)\n",
    "        \n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5551605e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "golf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
